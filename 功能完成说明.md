# 数据抓取模块功能说明

## ✅ 已完成功能

### 1. 数据抓取模块 (`app/crawler.py`)
- ✅ 创建了 `BaiduNewsCrawler` 爬虫类
- ✅ 实现了百度新闻搜索接口调用
- ✅ 实现了HTML解析和数据提取
- ✅ 支持自定义关键字搜索
- ✅ 支持设置最大返回结果数

### 2. 数据提取字段
- ✅ **标题** (title): 从h3标签中的链接提取
- ✅ **概要** (summary): 从搜索结果摘要中提取
- ✅ **封面** (cover): 从图片标签中提取
- ✅ **原始URL** (url): 从链接href中提取，支持百度跳转链接解析
- ✅ **来源** (source): 从来源信息中提取

### 3. 后端API接口
- ✅ `GET /crawler` - 数据抓取页面（需登录）
- ✅ `POST /api/crawler/search` - 数据抓取接口（需登录）

### 4. 前端页面
- ✅ 创建了数据抓取页面 (`templates/crawler.html`)
- ✅ 搜索表单（关键字输入、结果数量设置）
- ✅ 结果展示区域（标题、概要、来源、URL、封面）
- ✅ 响应式设计，使用Layui组件

### 5. 菜单集成
- ✅ 在Dashboard左侧菜单中添加了"数据抓取"入口

## 📋 技术实现

### 依赖库
- `requests`: HTTP请求
- `beautifulsoup4`: HTML解析
- `lxml`: HTML解析器

### 请求配置
- 使用提供的Request Headers
- 支持百度新闻搜索参数
- 处理百度跳转链接

### 数据解析
- 主要使用h3标签定位新闻标题
- 从父容器中提取摘要、来源等信息
- 支持多种HTML结构的容错处理

## 🚀 使用方法

### 1. 访问页面
登录后，在左侧菜单点击"数据抓取"，或直接访问：
```
http://localhost:5000/crawler
```

### 2. 输入关键字
在搜索表单中输入要搜索的关键字，例如：
- 西昌
- 舆情
- 新闻

### 3. 设置结果数量
可以设置要抓取的结果数量（1-50条）

### 4. 开始抓取
点击"开始抓取"按钮，系统会：
1. 调用百度新闻搜索接口
2. 解析返回的HTML
3. 提取新闻数据
4. 在页面上展示结果

## 📝 注意事项

1. **网络连接**: 需要能够访问百度网站
2. **反爬虫**: 百度可能有反爬虫机制，如果抓取失败可能是：
   - 请求频率过高
   - IP被限制
   - 页面结构变化
3. **数据准确性**: 由于网页结构可能变化，解析结果可能需要根据实际情况调整
4. **性能**: 建议合理设置结果数量，避免请求时间过长

## 🔧 后续优化建议

1. **缓存机制**: 对相同关键字的搜索结果进行缓存
2. **异步处理**: 对于大量数据，可以使用异步任务处理
3. **数据存储**: 将抓取的数据保存到数据库
4. **定时任务**: 支持定时自动抓取
5. **数据导出**: 支持将抓取结果导出为Excel或CSV

## 📊 数据格式

返回的数据格式：
```json
{
    "success": true,
    "message": "成功抓取 10 条数据",
    "data": [
        {
            "title": "新闻标题",
            "summary": "新闻摘要",
            "cover": "封面图片URL",
            "url": "原始URL",
            "source": "来源"
        }
    ],
    "count": 10
}
```

